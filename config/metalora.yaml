run_name: metalora
seed: 322
run_strategy: epoch
run_duration: 1
dry_run: false
model:
  name: TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T
  max_seq_length: 2048
  chunk_size: 512
optimizer:
  name: adamw
  learning_rate: 0.0002
  weight_decay: 0.0
  betas:
  - 0.9
  - 0.95
  decay_norm_and_bias: false
  decay_embeddings: false
  metrics_log_interval: null
deepspeed:
  enabled: true
  stage: 2
  offload_optimizer: false
  offload_param: false
scheduler:
  name: cosine_annealing
  units: by_steps
  t_warmup: 100
  t_method: linear
  t_factor: 0.1
  t_min: 1.0e-06
  grad_clip_warmup_steps: null
  grad_clip_warmup_factor: null
data:
  paths: pile
  num_workers: 2
  drop_last: true
  pin_memory: true
  prefetch_factor: null
  persistent_workers: false
  timeout: 0
checkpoint:
  save_interval: 1000
  save_interval_unsharded: null
  save_interval_ephemeral: null
  save_num_checkpoints_to_keep: 1
  save_num_unsharded_checkpoints_to_keep: -1
  force_save_unsharded: false
wandb:
  enabled: false
  project: null
  entity: CustomTrainer
  group: null
  name: null
  tags:
  - watching
  log_artifacts: false
  rank_zero_only: true
  log_interval: 1
speed_monitor:
  window_size: 100
  gpu_flops_available: null
fsdp:
  enabled: false
  use_orig_params: true
  sharding_strategy: FULL_SHARD
  wrapping_strategy: null
  precision: pure

restore_dataloader: true
fast_forward_batches: null

# eval
evaluators:
  type: ["perplexity"]
  data:
    paths: /home/aiscuser/sflora_data/pg19/349.txt
eval_interval: 100

# save
save_folder: ./
save_overwrite: false

# loading
load_path: null
load_path_sharded_checkpointer: null
reset_optimizer_state: false
reset_trainer_state: false
sharded_checkpointer: torch_legacy

# batch
device_train_batch_size: 2
device_eval_batch_size: 2

console_log_interval: 1
compile: null

time_limit: 171000.0
early_stopping_factor: null
save_data_indices: true
python_profiling: false
torch_profiling: false
stop_at: null
activation_checkpointing: null

# gradient accumulation, norm, and precision
gradient_accumulation_steps: 1
max_grad_norm: 1.0
precision: bf16
accelerator_type: "gpu"

